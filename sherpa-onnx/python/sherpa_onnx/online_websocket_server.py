from typing import List
from _sherpa_onnx import start_server

def dict_to_string(d : dict) -> str :
    return " ".join([f"--{k.replace('_', '-')}={v}" for k, v in d.items()])
    
class OnlineWebSocketServer(object):
    def __init__(self,
        port: int = 8080,
        tokens: str = "/path/to/tokens.txt",
        encoder: str = "/path/to/encoder.onnx",
        decoder: str = "/path/to/decoder.onnx",
        joiner: str = "/path/to/joiner.onnx",
        provider: str = 'cpu',
        log_file: str = "./log.txt",
        model_type: str = '',
        modeling_unit: str = 'bpe',
        bpe_vocab: str = '',
        max_batch_size: int = 5,
        loop_interval_ms: int = 10,
        device: int = 0,
        num_threads: int = 1,
        num_io_threads: int = 2,
        num_work_threads: int = 3,
        decoding_method: str = 'greedy_search',
        hotwords_score: float = 1.5,
        hotwords_file: str = '',
        blank_penalty: float = 0,
        temperature_scale: float = 2,
        end_tail_padding: float = 0.8,
        max_active_paths: int = 4,
        rule_fsts: str = '',
        low_freq: int = 20,
        feat_dim: int = 80,
        dither: int = 0,
        high_freq: int = -400,
        sample_rate: int = 8000,
        enable_endpoint: bool = True,
        rule1_min_trailing_blanks: int = 2,
        rule1_min_utterance_length: int = 0,
        rule1_must_contain_nonsilence: bool = False,
        rule1_min_trailing_silence: float = 2.4,
        rule2_min_trailing_blanks: int = 2,
        rule2_min_utterance_length: int = 0,
        rule2_must_contain_nonsilence: bool = True,
        rule2_min_trailing_silence: float = 1.2,
        rule3_min_trailing_blanks: int = 2,
        rule3_min_trailing_silence: int = 0,
        rule3_must_contain_nonsilence: bool = False,
        rule3_min_utterance_length: int = 20,
        lm_num_threads: int = 1,
        lm_provider: str = 'cpu',
        lm: str = '',
        lm_scale: float = 0.5,
        rule_fars: str = '',
        nemo_ctc_model: str = '',
        zipformer2_ctc_model: str = '',
        wenet_ctc_num_left_chunks: int = 4,
        wenet_ctc_model: str = '',
        wenet_ctc_chunk_size: int = 16,
        paraformer_encoder: str = '',
        paraformer_decoder: str = '',
        ctc_graph: str = '',
        ctc_max_active: int = 3000,
        config: str = '',
        help: bool = False,
        print_args: bool = True,
        warm_up: int = 0,
        cuda_cudnn_conv_algo_search: int = 1,
        trt_fp16_enable: bool = True,
        trt_max_partition_iterations: int = 10,
        trt_min_subgraph_size: int = 5,
        trt_max_workspace_size: int = 2147483647,
        trt_timing_cache_enable: bool = True,
        trt_timing_cache_path: str = '.',
        trt_engine_cache_enable: bool = True,
        trt_engine_cache_path: str = '.',
        trt_dump_subgraphs: bool = False,
        trt_detailed_build_log: bool = False,
        debug: bool = False,
        ) :
        
        server_args = {
            "port": port,
            "tokens": tokens,
            "encoder": encoder,
            "decoder": decoder,
            "joiner": joiner,
            "provider": provider,
            "log-file": log_file,
            "model-type": model_type,
            "modeling-unit": modeling_unit,
            "bpe-vocab": bpe_vocab,
            "max-batch-size": max_batch_size,
            "loop-interval-ms": loop_interval_ms,
            "device": device,
            "num-threads": num_threads,
            "num-io-threads": num_io_threads,
            "num-work-threads": num_work_threads,
            "decoding-method": decoding_method,
            "hotwords-score": hotwords_score,
            "hotwords-file": hotwords_file,
            "blank-penalty": blank_penalty,
            "temperature-scale": temperature_scale,
            "end-tail-padding": end_tail_padding,
            "max-active-paths": max_active_paths,
            "rule-fsts": rule_fsts,
            "low-freq": low_freq,
            "feat-dim": feat_dim,
            "dither": dither,
            "high-freq": high_freq,
            "sample-rate": sample_rate,
            "enable-endpoint": enable_endpoint,
            "rule1-min-trailing-blanks": rule1_min_trailing_blanks,
            "rule1-min-utterance-length": rule1_min_utterance_length,
            "rule1-must-contain-nonsilence": rule1_must_contain_nonsilence,
            "rule1-min-trailing-silence": rule1_min_trailing_silence,
            "rule2-min-trailing-blanks": rule2_min_trailing_blanks,
            "rule2-min-utterance-length": rule2_min_utterance_length,
            "rule2-must-contain-nonsilence": rule2_must_contain_nonsilence,
            "rule2-min-trailing-silence": rule2_min_trailing_silence,
            "rule3-min-trailing-blanks": rule3_min_trailing_blanks,
            "rule3-min-trailing-silence": rule3_min_trailing_silence,
            "rule3-must-contain-nonsilence": rule3_must_contain_nonsilence,
            "rule3-min-utterance-length": rule3_min_utterance_length,
            "lm-num-threads": lm_num_threads,
            "lm-provider": lm_provider,
            "lm": lm,
            "lm-scale": lm_scale,
            "rule-fars": rule_fars,
            "nemo-ctc-model": nemo_ctc_model,
            "zipformer2-ctc-model": zipformer2_ctc_model,
            "wenet-ctc-num-left-chunks": wenet_ctc_num_left_chunks,
            "wenet-ctc-model": wenet_ctc_model,
            "wenet-ctc-chunk-size": wenet_ctc_chunk_size,
            "paraformer-encoder": paraformer_encoder,
            "paraformer-decoder": paraformer_decoder,
            "ctc-graph": ctc_graph,
            "ctc-max-active": ctc_max_active,
            "config": config,
            "help": help,
            "print-args": print_args,
            "warm-up": warm_up,
            "cuda-cudnn-conv-algo-search": cuda_cudnn_conv_algo_search,
            "trt-fp16-enable": trt_fp16_enable,
            "trt-max-partition-iterations": trt_max_partition_iterations,
            "trt-min-subgraph-size": trt_min_subgraph_size,
            "trt-max-workspace-size": trt_max_workspace_size,
            "trt-timing-cache-enable": trt_timing_cache_enable,
            "trt-timing-cache-path": trt_timing_cache_path,
            "trt-engine-cache-enable": trt_engine_cache_enable,
            "trt-engine-cache-path": trt_engine_cache_path,
            "trt-dump-subgraphs": trt_dump_subgraphs,
            "trt-detailed-build-log": trt_detailed_build_log,
            "debug": debug
        }
        self.server_args = server_args
        start_server(dict_to_string(self.server_args))

    def __init__(self, server_args : List[str]) :
        start_server(server_args)