name: export-paraformer-to-ascend-npu

on:
  push:
    branches:
      - ascend-npu-310
  workflow_dispatch:

concurrency:
  group: export-paraformer-to-ascend-nput-${{ github.ref }}
  cancel-in-progress: true

jobs:
  export-paraformer-to-rknn:
    if: github.repository_owner == 'k2-fsa' || github.repository_owner == 'csukuangfj'
    name: ${{ matrix.framework }} ${{ matrix.soc_version }}
    runs-on: ubuntu-latest

    strategy:
      fail-fast: false
      matrix:
        include:
          # ===== Ascend 910B =====
          - soc_version: "910B"
            image: "gpustack/ascendai-cann:8.0.RC3-910b-ubuntu20.04-py3.9"
            framework: "FunASR"

          - soc_version: "910B"
            image: "gpustack/ascendai-cann:8.0.RC3-910b-ubuntu20.04-py3.9"
            framework: "WSChuan-ASR"

          # ===== Ascend 310 =====
          - soc_version: "310P3"
            # image: "gpustack/ascendai-cann:8.0.RC2.alpha003-310p-ubuntu20.04-py3.9"
            image: "gpustack/devel-ascendai-cann:8.0.rc3.beta1-310p-ubuntu20.04-v2"
            framework: "FunASR"

          - soc_version: "310P3"
            # image: "gpustack/ascendai-cann:8.0.RC2.alpha003-310p-ubuntu20.04-py3.9"
            image: "gpustack/devel-ascendai-cann:8.0.rc3.beta1-310p-ubuntu20.04-v2"
            framework: "WSChuan-ASR"

    container:
      # image: ascendai/cann:latest
      # image: ascendai/cann:8.1.rc1-910b-ubuntu22.04-py3.10
      # see https://hub.docker.com/r/gpustack/ascendai-cann/tags?name=8.0
      # see https://hub.docker.com/r/gpustack/devel-ascendai-cann/tags?name=310p
      image: ${{ matrix.image }}

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python 3.8
        uses: actions/setup-python@v5
        with:
          python-version: "3.8"

      - name: Show Python
        shell: bash
        run: |
          python3 --version
          which python3

      - name: Install curl
        shell: bash
        run: apt-get update && apt-get install -y curl bzip2

      - name: Verify environment
        shell: bash
        run: |
          ls -lh /usr/local/Ascend/ascend-toolkit/set_env.sh

          find /usr/local/Ascend -name "libascend*.so" 2>/dev/null


          source /usr/local/Ascend/ascend-toolkit/set_env.sh
          export LD_LIBRARY_PATH=/usr/local/Ascend/ascend-toolkit/latest/x86_64-linux/devlib/linux/x86_64:$LD_LIBRARY_PATH

          echo "CANN environment:"
          which atc || echo "atc not found"
          atc --help

      - name: Install Python dependencies
        shell: bash
        run: |
          python3 -m pip install "numpy<2" \
                  onnx==1.17.0 \
                  torch==2.0.0+cpu -f https://download.pytorch.org/whl/torch \
                  attrs psutil scipy decorator cloudpickle ml-dtypes tornado \
                  pyyaml

      - name: Setup tmate session
        if: false
        uses: mxschmitt/action-tmate@v3

      - name: Run Paraformer from FunAsr
        if: matrix.framework == 'FunASR'
        shell: bash
        run: |
          cd scripts/paraformer/ascend-npu

          curl -SL -O https://www.modelscope.cn/models/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/resolve/master/am.mvn
          curl -SL -O https://www.modelscope.cn/models/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/resolve/master/config.yaml
          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/tokens.txt

          curl -SL -O https://www.modelscope.cn/models/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/resolve/master/model.pt
          mv model.pt model_state_dict.pt

          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/test_wavs/0.wav
          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/test_wavs/1.wav
          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/test_wavs/2.wav
          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/test_wavs/3-sichuan.wav
          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/test_wavs/4-tianjin.wav
          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/test_wavs/5-henan.wav
          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/test_wavs/6-zh-en.wav
          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/test_wavs/8k.wav

          rm -f README.md || true

          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/README.md

          echo "export to onnx"

          python3 ./export_encoder_onnx.py
          python3 ./export_decoder_onnx.py
          python3 ./export_predictor_onnx.py

          ls -lh *.onnx

          source /usr/local/Ascend/ascend-toolkit/set_env.sh
          export LD_LIBRARY_PATH=/usr/local/Ascend/ascend-toolkit/latest/x86_64-linux/devlib/linux/x86_64:$LD_LIBRARY_PATH

          soc_version=${{ matrix.soc_version }}

          atc --model=./predictor.onnx \
            --framework=5 \
            --host_env_os=linux \
            --host_env_cpu=aarch64 \
            --output=predictor \
            --input_format=ND \
            --input_shape="encoder_out:1,-1,512" \
            --soc_version="Ascend${soc_version}"

          ls -lh *.om

          atc --model=./decoder.onnx \
            --framework=5 \
            --host_env_os=linux \
            --host_env_cpu=aarch64 \
            --output=decoder \
            --input_format=ND \
            --input_shape="encoder_out:1,-1,512;acoustic_embedding:1,-1,512" \
            --soc_version="Ascend${soc_version}"

          ls -lh *.om

          atc --model=./encoder.onnx \
            --framework=5 \
            --host_env_os=linux \
            --host_env_cpu=aarch64 \
            --output=encoder \
            --input_format=ND \
            --input_shape="x:1,-1,560" \
            --soc_version="Ascend${soc_version}"

          ls -lh *.om


          echo "collect results"
          d=sherpa-onnx-ascend-910B-paraformer-zh-2023-03-28

          mkdir -p $d
          mkdir -p $d/test_wavs

          cp -v README.md $d
          cp -v encoder_linux_aarch64.om $d/encoder.om
          cp -v decoder_linux_aarch64.om $d/decoder.om
          cp -v predictor_linux_aarch64.om $d/predictor.om
          cp -v test_om.py $d/

          cp -v tokens.txt $d
          cp -v *.wav $d/test_wavs
          ls -lh $d
          tar cjfv $d.tar.bz2 $d
          ls -lh *.tar.bz2
          rm -rf $d

          echo "----show---"
          ls -lh *.tar.bz2

          mv *.tar.bz2 ../../..

      - name: Run Paraformer from WSChuan-ASR
        if: matrix.framework == 'WSChuan-ASR'
        shell: bash
        run: |
          cd scripts/paraformer/ascend-npu

          curl -SL -O https://hf-mirror.com/csukuangfj/WSChuan-ASR/resolve/main/Paraformer-large-Chuan/am.mvn
          curl -SL -O https://hf-mirror.com/csukuangfj/WSChuan-ASR/resolve/main/Paraformer-large-Chuan/config.yaml
          curl -SL -O https://hf-mirror.com/csukuangfj/WSChuan-ASR/resolve/main/Paraformer-large-Chuan/tokens.json
          curl -SL -O https://hf-mirror.com/csukuangfj/WSChuan-ASR/resolve/main/Paraformer-large-Chuan/model_state_dict.pt

          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-int8-2025-10-07/resolve/main/tokens.txt


          for i in $(seq 1 16); do
            curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-int8-2025-10-07/resolve/main/test_wavs/$i.wav
          done

          rm -f README.md || true
          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-int8-2025-10-07/resolve/main/README.md

          echo "export to onnx"

          python3 ./export_encoder_onnx.py
          python3 ./export_decoder_onnx.py
          python3 ./export_predictor_onnx.py

          ls -lh *.onnx

          source /usr/local/Ascend/ascend-toolkit/set_env.sh
          export LD_LIBRARY_PATH=/usr/local/Ascend/ascend-toolkit/latest/x86_64-linux/devlib/linux/x86_64:$LD_LIBRARY_PATH

          soc_version=${{ matrix.soc_version }}

          atc --model=./predictor.onnx \
            --framework=5 \
            --host_env_os=linux \
            --host_env_cpu=aarch64 \
            --output=predictor \
            --input_format=ND \
            --input_shape="encoder_out:1,-1,512" \
            --soc_version="Ascend${soc_version}"

          ls -lh *.om

          atc --model=./decoder.onnx \
            --framework=5 \
            --host_env_os=linux \
            --host_env_cpu=aarch64 \
            --output=decoder \
            --input_format=ND \
            --input_shape="encoder_out:1,-1,512;acoustic_embedding:1,-1,512" \
            --soc_version="Ascend${soc_version}"

          ls -lh *.om

          atc --model=./encoder.onnx \
            --framework=5 \
            --host_env_os=linux \
            --host_env_cpu=aarch64 \
            --output=encoder \
            --input_format=ND \
            --input_shape="x:1,-1,560" \
            --soc_version="Ascend${soc_version}"

          ls -lh *.om


          echo "collect results"
          d=sherpa-onnx-ascend-${soc_version}-paraformer-zh-2025-10-07

          mkdir -p $d
          mkdir -p $d/test_wavs

          cp -v README.md $d
          cp -v encoder_linux_aarch64.om $d/encoder.om
          cp -v decoder_linux_aarch64.om $d/decoder.om
          cp -v predictor_linux_aarch64.om $d/predictor.om
          cp -v test_om.py $d/

          cp -v tokens.txt $d
          cp -v *.wav $d/test_wavs
          ls -lh $d
          tar cjfv $d.tar.bz2 $d
          ls -lh *.tar.bz2
          rm -rf $d

          echo "----show---"
          ls -lh *.tar.bz2

          mv *.tar.bz2 ../../..

      - name: Release
        if: github.repository_owner == 'csukuangfj'
        uses: svenstaro/upload-release-action@v2
        with:
          file_glob: true
          file: ./*.tar.bz2
          overwrite: true
          repo_name: k2-fsa/sherpa-onnx
          repo_token: ${{ secrets.UPLOAD_GH_SHERPA_ONNX_TOKEN }}
          tag: asr-models

      - name: Release
        if: github.repository_owner == 'k2-fsa'
        uses: svenstaro/upload-release-action@v2
        with:
          file_glob: true
          file: ./*.tar.bz2
          overwrite: true
          tag: asr-models
