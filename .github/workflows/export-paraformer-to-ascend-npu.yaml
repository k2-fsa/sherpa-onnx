name: export-paraformer-to-ascend-npu

on:
  push:
    branches:
      - ascend-npu
  workflow_dispatch:

# concurrency:
#   group: export-paraformer-to-ascend-nput-${{ github.ref }}
#   cancel-in-progress: true

jobs:
  export-paraformer-to-rknn:
    if: github.repository_owner == 'k2-fsa' || github.repository_owner == 'csukuangfj'
    name: ${{ matrix.framework }}
    runs-on: ${{ matrix.os }}
    container:
      image: ascendai/cann:latest
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest]
        python-version: ["3.8"]
        # framework: ["FunASR", "WSChuan-ASR"]
        framework: ["FunASR"]
        # framework: ["WSChuan-ASR"]

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Setup tmate session
        if: false
        uses: mxschmitt/action-tmate@v3

      - name: Show Python
        shell: bash
        run: |
          python3 --version

      - name: Verify environment
        shell: bash
        run: |
          ls -lh /usr/local/Ascend/ascend-toolkit/set_env.sh

          find /usr/local/Ascend -name "libascend*.so" 2>/dev/null


          source /usr/local/Ascend/ascend-toolkit/set_env.sh
          export LD_LIBRARY_PATH=/usr/local/Ascend/ascend-toolkit/latest/x86_64-linux/devlib/linux/x86_64:$LD_LIBRARY_PATH

          echo "CANN environment:"
          which atc || echo "atc not found"
          atc --help

      - name: Install Python dependencies
        shell: bash
        run: |
          python3 -m pip install "numpy<2" \
                  onnx==1.17.0 \
                  torch==2.0.0+cpu -f https://download.pytorch.org/whl/torch \
                  attrs psutil scipy decorator cloudpickle ml-dtypes tornado \
                  pyyaml


      - name: Run Paraformer from FunAsr
        if: matrix.framework == 'FunASR'
        shell: bash
        run: |
          cd scripts/paraformer/ascend-npu

          curl -SL -O https://www.modelscope.cn/models/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/resolve/master/am.mvn
          curl -SL -O https://www.modelscope.cn/models/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/resolve/master/config.yaml
          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/tokens.txt

          curl -SL -O https://www.modelscope.cn/models/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/resolve/master/model.pt
          mv model.pt model_state_dict.pt

          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/test_wavs/0.wav
          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/test_wavs/1.wav
          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/test_wavs/2.wav
          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/test_wavs/3-sichuan.wav
          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/test_wavs/4-tianjin.wav
          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/test_wavs/5-henan.wav
          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/test_wavs/6-zh-en.wav
          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/test_wavs/8k.wav

          rm -f README.md || true

          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-2023-03-28/resolve/main/README.md

          echo "export to onnx"

          python3 ./export_encoder_onnx.py

          ls -lh *.onnx

          source /usr/local/Ascend/ascend-toolkit/set_env.sh
          export LD_LIBRARY_PATH=/usr/local/Ascend/ascend-toolkit/latest/x86_64-linux/devlib/linux/x86_64:$LD_LIBRARY_PATH

          atc --model=./encoder.onnx \
            --framework=5 \
            --output=encoder_dynamic \
            --input_format=ND \
            --input_shape="x:1,10~500,560" \
            --soc_version="Ascend910B"

          ls -lh *.om

          echo "---"
          ls -lh *.rknn

          echo "collect results"
          d=sherpa-onnx-$p-$t-seconds-paraformer-zh-2023-03-28

          mkdir -p $d
          mkdir -p $d/test_wavs

          cp -v README.md $d
          cp -v encoder-$t-seconds.rknn $d/encoder.rknn
          cp -v decoder-$t-seconds.rknn $d/decoder.rknn
          cp -v predictor-$t-seconds.rknn $d/predictor.rknn

          cp -v tokens.txt $d
          cp -v *.wav $d/test_wavs
          ls -lh $d
          tar cjfv $d.tar.bz2 $d
          ls -lh *.tar.bz2
          rm -rf d

          echo "----show---"
          ls -lh *.tar.bz2

          mv *.tar.bz2 ../../..

      - name: Run Paraformer from WSChuan-ASR
        if: false
        # if: matrix.framework == 'WSChuan-ASR'
        shell: bash
        run: |
          cd scripts/paraformer/rknn

          curl -SL -O https://hf-mirror.com/csukuangfj/WSChuan-ASR/resolve/main/Paraformer-large-Chuan/am.mvn
          curl -SL -O https://hf-mirror.com/csukuangfj/WSChuan-ASR/resolve/main/Paraformer-large-Chuan/config.yaml
          curl -SL -O https://hf-mirror.com/csukuangfj/WSChuan-ASR/resolve/main/Paraformer-large-Chuan/tokens.json
          curl -SL -O https://hf-mirror.com/csukuangfj/WSChuan-ASR/resolve/main/Paraformer-large-Chuan/model_state_dict.pt

          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-int8-2025-10-07/resolve/main/tokens.txt


          for i in $(seq 1 16); do
            curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-int8-2025-10-07/resolve/main/test_wavs/$i.wav
          done

          rm -f README.md || true
          curl -SL -O https://huggingface.co/csukuangfj/sherpa-onnx-paraformer-zh-int8-2025-10-07/resolve/main/README.md

          echo "export to onnx"
          t=${{ matrix.input_in_seconds }}
          p=${{ matrix.platform }}

          export model_author="ASLP-lab"
          export comment="ASLP-lab/WSChuan-ASR"
          export url="https://huggingface.co/ASLP-lab/WSChuan-ASR/tree/main/Paraformer-large-Chuan"

          echo "----$t---"
          python3 ./export_encoder_onnx.py  --input-len-in-seconds $t
          python3 ./export_rknn.py --target-platform $p --in-model ./encoder-$t-seconds.onnx --out-model ./encoder-$t-seconds.rknn >/dev/null 2>&1

          python3 ./export_predictor_onnx.py  --input-len-in-seconds $t
          python3 ./export_rknn.py --target-platform $p --in-model ./predictor-$t-seconds.onnx --out-model ./predictor-$t-seconds.rknn >/dev/null 2>&1

          python3 ./export_decoder_onnx.py  --input-len-in-seconds $t
          python3 ./export_rknn.py --target-platform $p --in-model ./decoder-$t-seconds.onnx --out-model ./decoder-$t-seconds.rknn >/dev/null 2>&1

          ls -lh *.onnx
          echo "---"
          ls -lh *.rknn

          echo "collect results"
          d=sherpa-onnx-$p-$t-seconds-paraformer-zh-2025-10-07

          mkdir -p $d
          mkdir -p $d/test_wavs

          cp -v README.md $d
          cp -v encoder-$t-seconds.rknn $d/encoder.rknn
          cp -v decoder-$t-seconds.rknn $d/decoder.rknn
          cp -v predictor-$t-seconds.rknn $d/predictor.rknn

          cp -v tokens.txt $d
          cp -v *.wav $d/test_wavs
          ls -lh $d
          tar cjfv $d.tar.bz2 $d
          ls -lh *.tar.bz2
          rm -rf d

          echo "----show---"
          ls -lh *.tar.bz2

          mv *.tar.bz2 ../../..

      - name: Release
        # if: github.repository_owner == 'csukuangfj'
        if: false
        uses: svenstaro/upload-release-action@v2
        with:
          file_glob: true
          file: ./*.tar.bz2
          overwrite: true
          repo_name: k2-fsa/sherpa-onnx
          repo_token: ${{ secrets.UPLOAD_GH_SHERPA_ONNX_TOKEN }}
          tag: asr-models

      - name: Release
        # if: github.repository_owner == 'k2-fsa'
        if: false
        uses: svenstaro/upload-release-action@v2
        with:
          file_glob: true
          file: ./*.tar.bz2
          overwrite: true
          tag: asr-models
